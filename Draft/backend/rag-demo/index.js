import fs from "fs-extra";
import path from "path";
import { OllamaEmbeddings, ChatOllama } from "@langchain/ollama";

// ---------------------
// 1ï¸âƒ£ è‡ªå®šä¹‰å†…å­˜å‘é‡åº“
// ---------------------
class SimpleVectorStore {
	constructor(embeddings) {
		this.embeddings = embeddings;
		this.docs = [];
	}

	async addDocuments (docs) {
		for (const doc of docs) {
			// âš  æ³¨æ„æ–°ç‰ˆ API
			const [vector] = await this.embeddings.embedDocuments([doc.pageContent]);
			this.docs.push({ ...doc, vector });
		}
	}

	async similaritySearch (query, k = 3) {
		const qVec = await this.embeddings.embedQuery(query); // æŸ¥è¯¢å‘é‡
		const scored = this.docs.map(doc => ({
			doc,
			score: cosineSimilarity(doc.vector, qVec)
		}));
		return scored
			.sort((a, b) => b.score - a.score)
			.slice(0, k);
	}
}


// ä½™å¼¦ç›¸ä¼¼åº¦
function cosineSimilarity (a, b) {
	const dot = a.reduce((sum, v, i) => sum + v * b[i], 0);
	const magA = Math.sqrt(a.reduce((sum, v) => sum + v * v, 0));
	const magB = Math.sqrt(b.reduce((sum, v) => sum + v * v, 0));
	return dot / (magA * magB);
}

// ---------------------
// 2ï¸âƒ£ åˆå§‹åŒ– Ollama Embeddings + LLM
// ---------------------
const embeddings = new OllamaEmbeddings({
	model: "deepseek-r1:8b" // æ›¿æ¢ä¸ºä½ æœ¬åœ° Ollama æ¨¡å‹
});

const llm = new ChatOllama({
	model: "deepseek-r1:8b"
});

const vectorStore = new SimpleVectorStore(embeddings);

// ---------------------
// 3ï¸âƒ£ ä¸Šä¼ æ–‡ç« 
// ---------------------
async function uploadArticle (filePath, link) {
	const content = await fs.readFile(filePath, "utf-8");
	await vectorStore.addDocuments([
		{
			pageContent: content,
			metadata: {
				link,
				title: path.basename(filePath)
			}
		}
	]);
	console.log(`âœ… ä¸Šä¼ æˆåŠŸï¼š${filePath}`);
}

// ---------------------
// 4ï¸âƒ£ æŸ¥è¯¢å‡½æ•°
// ---------------------
async function askUser (query) {
	const results = await vectorStore.similaritySearch(query, 5);

	const context = results
		.map(({ doc }) => `ã€æ–‡ç« ï¼š${doc.metadata.title}ã€‘\n${doc.pageContent}\n`)
		.join("\n");

	const stream = await llm.stream(`
ç”¨æˆ·é—®é¢˜ï¼š${query}

ä»¥ä¸‹æ˜¯ç›¸å…³æ–‡æ¡£ï¼Œè¯·ç»™å‡ºï¼š
1) æœ€æ­£ç¡®çš„ç­”æ¡ˆ
2) å¿…è¦çš„è¡¥å……è¯´æ˜
3) æŒ‰åŒ¹é…åº¦é«˜åˆ°ä½åˆ—å‡ºå¯¹åº”é“¾æ¥
4) å¯¹åº”æ–‡ç« çš„é“¾æ¥

æ–‡æ¡£å†…å®¹ï¼š
${context}
`);

	let answer = "";
	for await (const chunk of stream) {
		// âœ… å–æ–‡æœ¬
		answer += chunk.text ?? chunk.delta ?? "";
	}

	console.log("\nğŸ¤– å›ç­”ï¼š\n", answer);
}


// ---------------------
// 5ï¸âƒ£ ç¤ºä¾‹è¿è¡Œ
// ---------------------
async function main () {
	await uploadArticle("./docs/a1.txt", "https://example.com/a1");
	await uploadArticle("./docs/a2.txt", "https://example.com/a2");
	await uploadArticle("./docs/a3.txt", "https://example.com/a3");

	await askUser("ä½ çŸ¥é“ä¼ ç»™ä½ çš„å­¦ä¹ æ–‡ä»¶çš„é“¾æ¥å—");
}

main();
